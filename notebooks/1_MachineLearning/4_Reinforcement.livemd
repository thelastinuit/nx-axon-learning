# Machine Learning / Reinforcement Learning

## Section

```elixir
Mix.install([
  {:essence, "~> 0.2.0"},
  {:req, "~> 0.3.0"},
  {:kino_vega_lite, "~> 0.1.3"}
])
```

## Goal

This lesson covers the reinforcement learning type of machine learning. After this lesson you will have an overview and example of supervised learning, including its applications and challenges.

## Introduction

Reinforcement learning is learning through trial and error. Reinforcement learning is a way for machine learning in an unknown environment with only sensory input combined with rewards and punishments. Humans learn through reinforcement; when an action is rewarded, the action is reinforced. When an action is punished, the action is not reinforced.

![](images/mousemaze.png)

## Example

A machine can learn to play a video game. The sensory inputs are the graphics and the rewards are the points. Reinforcement Learning problems are closed-loop problems. Inputs are not provided like with Supervised Learning. The learning is discovered by trying out all the available options and learning which actions lead to the highest reward.

<!-- livebook:{"break_markdown":true} -->

### How It Works

For a machine, Reinforcement Learning means a set of actions must be available. As each action is tried it is observed whether it was successful (reward) or not (punishment). If a sequence of actions leads to success, then the individual steps are linked to part of the success. If a long sequence of actions is necessary before the feedback is received, it can take a long time for learning to happen. It is preferable for more frequent feedback to occur along the sequence of actions so the machine can learn and make corrections more frequently.

![](images/rewards.png)

## Applications

The most common applications for Reinforcement Learning involve mechanical systems. This includes robotics, flight simulation, and autonomous driving. Thinking of the videos of robots learning to maneuver in a new environment and learn all over again if they are damaged.

![](images/robot.png)

## Challenges

Reinforcement Learning isn't the best choice if the cost of using trial and error is too high or if it takes too long to try the actions before getting feedback. For example, Reinforcement Learning is not a good choice for stock market forecasting. Each bad choice costs money.

<!-- livebook:{"break_markdown":true} -->

<hr style="background-color: #800080;height: 15.0px;" />

## Brain Break!

<span style="color: #800080; font-size: 24px; font-weight: bold;">
Time for some Elixir
</span>

<img src="https://static.thenounproject.com/png/1111032-200.png" alt="Brain icon" style="width: 85px; float: left; margin-bottom: 10px; margin-right: 20px;" />

Take a break and explore an Elixir library called [Essence](https://github.com/nicbet/essence). It is a Natural Language Processing (NLP) and Text Summarization Library. NLP brings together the fields of linguistics and AI to explore how computers can understand text and spoken words like human beings can.

To make the most of this library we need a document. For ours we'll use [Req](https://github.com/wojtekmach/req) to get a short story from Project Gutenburg: The Yellow Wallpaper by Charlotte Perkins.

Essence provides a convenience method for reading the plain text.

```elixir
doc =
  "https://www.gutenberg.org/files/1952/1952-0.txt"
  |> Req.get!()
  |> Map.get(:body)
  |> Essence.Document.from_text()
```

Take a look at how many tokens are contained in the story:

```elixir
doc |> Essence.Document.enumerate_tokens() |> Enum.count()
```

Grab the first sentence.

```elixir
doc |> then(fn d -> Essence.Document.sentence(d, 0) end)
```

We can compute the frequency distribution of the tokens:

```elixir
fd = doc |> Essence.Vocabulary.freq_dist()
```

Essence can tell us the unique set of dictionary words in the story, called the `Vocabulary`:

```elixir
vocabulary = doc |> Essence.Vocabulary.vocabulary()
```

The top 10 most frequently occurring tokens:

```elixir
top_tokens =
  vocabulary
  |> Enum.sort_by(fn x -> Map.get(fd, x) end, &>=/2)
  |> Enum.slice(1, 10)
```

Get the diversity of the vocabulary using Essense's lexical richness. It is the number of tokens divided by the size of the vocabulary above.

```elixir
doc |> Essence.Vocabulary.lexical_richness()
```

Get a concordance view of 'wallpaper'; note it doesn't match on 'wallpaper' as it is matching on tokens. Try other words.

```elixir
doc |> Essence.Document.concordance("paper")
```

##### Challenge

What would you add to this library? How could it be of use to you in your current projects? Could you do sentiment analysis on only the most frequent words in your customer communication or GitHub PRs? Could the concordance feature give you a sense for what words appear near high frequency words?

<!-- livebook:{"break_markdown":true} -->

##### Challenge

What would you add to this library? How could it be of use to you in your current projects? Could you do sentiment analysis on only the most frequent words in your customer communication or GitHub PRs? Could the concordance feature give you a sense for what words appear near high frequency words?

<!-- livebook:{"break_markdown":true} -->

<hr style="background-color: #800080;height: 15.0px;" />

<!-- livebook:{"break_markdown":true} -->

[<span style="float: left; color: #800080; font-weight: bold; font-family: FreeMono, monospace">< previous</span>](3_Unsupervised.livemd)

[<span style="float: right; color: #800080; font-weight: bold; font-family: FreeMono, monospace">next chapter: Statistics></span>](../2_Statistics/1_Intro.livemd)
